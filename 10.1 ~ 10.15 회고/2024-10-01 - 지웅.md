# 📝 2024.10.01 회고 📝
#### 1. 수업 내용 복습정리
#### 2. 백준

---------------------------------

### PyTorch 학습
#####  PyTorch 프레임워크를 이용해 머신러닝 및 딥러닝 모델을 구현

- PyTorch 기본 설정 및 텐서 연산: 텐서(tensor)의 생성, 크기 변환, 연산 등 PyTorch의 기본적인 텐서 조작 방법을 다룸.
  
- 신경망 모델 구축: torch.nn 모듈을 사용하여 간단한 신경망 모델을 구현하고, 다양한 층(layer)을 쌓는 방법을 설명함.
  
- 데이터셋 및 데이터 로더 사용: torch.utils.data.Dataset과 torch.utils.data.DataLoader를 사용해 데이터셋을 로드하고 전처리하는 방법을 다룸.
  
- 손실 함수와 옵티마이저 설정: torch.optim 모듈을 이용해 손실 함수와 옵티마이저를 설정하고, 모델 학습 과정을 구현함.
 
- 모델 학습 및 평가: 학습 루프를 작성하여 모델을 훈련하고, 테스트 데이터셋으로 성능을 평가하는 방법을 다룸.


### TensorFlow 학습
##### TensorFlow 프레임워크를 사용하여 모델을 구현하고 학습

- TensorFlow 기본 설정 및 텐서 연산: tf.constant와 tf.Variable을 이용하여 텐서를 생성하고, 텐서 간 연산 수행.

- Keras를 사용한 모델 구축: tf.keras.Sequential API를 사용해 간단한 모델을 설계하고, 여러 층을 쌓아 모델을 구성함.

- 데이터셋 준비 및 전처리: tf.data.Dataset을 사용하여 데이터를 로드하고, 훈련 및 평가용 데이터셋을 준비하는 방법을 다룸.

- 손실 함수 및 옵티마이저 설정: tf.keras.losses와 tf.keras.optimizers를 이용해 모델의 손실 함수와 옵티마이저를 설정함.

- 모델 학습 및 평가: 모델 학습 과정을 설정하고, model.fit() 메서드를 사용해 모델을 훈련 및 평가하는 방법을 설명함.

### PyTorch로 구현한 DNN(Deep Neural Network) 모델

- DNN 모델 구축: torch.nn.Module을 사용해 심층 신경망(Deep Neural Network)을 구현하고, 입력, 은닉층, 출력층을 포함한 다층 모델을 구성.

- 데이터셋 로드 및 전처리: torch.utils.data.DataLoader를 사용해 데이터를 불러오고, 훈련과 테스트 데이터로 분할.

- 모델 학습 및 손실 시각화: 학습 루프를 구성하고, 학습 과정에서 손실 값을 기록하여 시각화.

- 모델 평가: 정확도, 손실 값을 기반으로 모델을 평가하고, 테스트 데이터에 대한 성능 측정.

### PyTorch와 TensorFlow의 기본적인 차이점
###### PyTorch:
- 동적 계산 그래프(Dynamic Computation Graph): 모델을 정의할 때 그래프가 즉시 생성되어 수정이 용이함.
- 직관적이고 유연한 모델 작성: Pythonic한 코드 스타일로 디버깅이 쉽고, 연구 및 실험 목적에 많이 사용됨.
- GPU 가속: torch.cuda 모듈을 사용해 GPU에서 텐서 연산을 수행할 수 있음.

###### TensorFlow:
- 정적 계산 그래프(Static Computation Graph): 그래프를 미리 정의하고 실행, 최적화하여 효율적으로 연산.
- Keras API와의 통합: tf.keras를 통해 간단하고 빠르게 모델을 작성할 수 있으며, 직관적인 인터페이스를 제공.
- 배포와 확장성: 모바일, 웹, 서버 등 다양한 플랫폼에 모델을 배포할 수 있는 도구와 옵션을 제공함.


### 딥러닝 모델 구축 및 학습

- 모델 구성: 두 프레임워크 모두 기본적인 모델 구축을 지원하며, 신경망을 층(layer) 단위로 쌓아 구현할 수 있음.
  - PyTorch는 torch.nn.Module을 상속하여 모델을 구성하며, forward 메서드를 통해 순전파(forward propagation)를 정의.
  - TensorFlow는 tf.keras.Sequential을 사용해 각 층을 순서대로 쌓아 모델을 구성함.

- 손실 함수와 옵티마이저:
  - PyTorch의 torch.optim을 사용하여 SGD, Adam 등 다양한 옵티마이저를 설정하고, torch.nn의 손실 함수를 사용.
  - TensorFlow는 tf.keras.losses와 tf.keras.optimizers 모듈을 사용해 손실 함수와 옵티마이저를 설정.

- 모델 학습 및 평가:
  - PyTorch는 학습 루프를 직접 작성하여 모델을 훈련시키고, 손실과 정확도를 출력함.
  - TensorFlow는 model.fit() 메서드를 통해 간편하게 학습을 진행하고, model.evaluate()를 통해 성능을 평가.

### PyTorch DNN 구현

- 다층 신경망(Deep Neural Network) 구성: 입력층, 여러 개의 은닉층, 출력층으로 구성된 심층 신경망을 구현하여 복잡한 데이터셋에 대한 학습을 수행함.

- 모델 최적화: torch.optim.Adam 옵티마이저를 사용하여 모델을 최적화하고, CrossEntropyLoss를 사용해 분류 문제의 손실을 계산.

- 손실 값 시각화: 학습 과정에서 손실 값이 어떻게 변화하는지 시각화하여 학습 성과를 모니터링함.


### 내용 요약

- PyTorch와 TensorFlow의 기초적인 사용 방법을 학습

- 텐서 생성, 연산, 모델 구축, 학습 및 평가의 단계별 구현 방법을 각각의 프레임워크에서 설명

- 딥러닝 모델을 구축하는 기본적인 방법과 프레임워크 간의 차이점을 파악하고, 이를 통해 어떤 상황에서 각 프레임워크를 사용할지에 대해 이해 및 PyTorch의 동적 그래프와 TensorFlow의 정적 그래프, Keras API 사용법의 차이 이해.

- DNN 모델 구현 및 학습을 통해 다층 신경망을 구현하고, 학습 및 평과 과정을 통해 모델 성능을 시각화 및 평가해봄






```

