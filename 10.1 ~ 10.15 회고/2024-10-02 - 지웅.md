# 📝 2024.10.02 회고 📝
#### 1. 수업 내용 복습정리
#### 2. 백준

---------------------------------

# CNN모델의 이해
## CNN (Convolutional Neural Network) 모델
- 최근의 영상 인식, 처리 분야에 있어서 가장 기본이 되는 모델
- 눈과 뇌에서 처리되는 신경과학적 시각처리 방식에서 고안한 모델
- 신경망 동작을 처리하기 위하여 합성곱 연산을 이용함
  - 합성곱: 두 개의 함수가 있을 때, 둘 중에서 하나의 함수를 반전, 이동(전이)시킨 후, 두 함수를 곱한(결합한) 결과 를 적분하여 그 파형(그래프)을 얻는 연산 방법
  - CNN 모델에서는 합성곱 연산을 기반으로 각 영역(픽셀)이 서로 얼마나 일치하는지 계산하여 그  계산 결과를 활
용함

### Convolution (합성곱)
![image](https://github.com/user-attachments/assets/daf730c3-0961-440d-a642-d27734f114c9)

- 합성곱 신경망에서는 “하나의 함수가 다른 함수와 얼마나 일치하는가?”의 의미로 사용

- 하나의 필터(커널)에 대하여 이미지의 각 부분들이 필터와 얼마나 일치하는지 계산

![image](https://github.com/user-attachments/assets/b47e523e-bcaa-43b2-ac80-2462d55a8919)
- 가운데 부분에 있는 정사각형이 필터

### CNN 모델
- Convolution(합성곱) 을 이용하여 가중치 수 줄임 → 연산량 감소와 효과적인 이미지 처리 수행 (위 사진에서 9개의 값이 weight(가중치))
- Convolution Filter 를 이용하여 신경망 동작 수행
- Convolution Layer 와 Fully Connected Layer 를 중심으로 영상정보 처리
  - Convolution Layer : 특징점을 효과적으로 찾는 데 활용
  - Fully Connected Layer : 발견한 특징점을 기반으로 이미지를 분류하는 데 활용
 
### 기본구조
![image](https://github.com/user-attachments/assets/6f2ed7d8-5517-4f88-b964-dc8d5b4fb03f)

- Convolution Layer - Pooling Layer의 반복
- 반복 방식은 사용자가 임의로 결정 (예, Convolution Layer만 여러 층을 가진 후 마지막에 Pooling Layer가 오는 경우도 있음)
- 국소/지역 콘트라스트 정규화 (Local Contrast Normalization, LCN) 층을 매치하는 경우도 있음

### 합성곱 층 (Convolution Layer)
- 목적 : 테두리, 선, 색 등 이미지의 시각적 특징이나 특성 감지
![image](https://github.com/user-attachments/assets/141821e7-8e74-4e48-864a-b4a3b02f152b)

- 패딩
  - 더 좋은 결과를 내기 위해 윈도우를 이미지 영역 밖으로 확장할 때 사용
![image](https://github.com/user-attachments/assets/eb444a0c-6d28-4019-a23e-caa7a456c69e)

### Convolution Layer 에서의 연산
- Convolution, 즉 합성곱이란 이미지와 필터 사이에 정의되는 합성 곱 연산을 말함
- 이미지의 합성곱은 필터의 명암 패턴과 유사한 명암 패턴이 입력된 이미지의 어디에 있는지 검출하는 작용, 즉 필터가 나타내는 특징적인 명암 구조를 이미지로부터 추출하는 작용을 함
- 필터: 커널이라고도 함
  - 입력층의 윈도우를 은닉층의 뉴런 하나로 압축할 때, Convolution Layer에서는 윈도우의 크기만큼의 가중치와 1개의 편향 값(bias)을 적용
  - 예를 들어 윈도우의 크기가 5x5라면 5x5개의 가중치와 1개의 편향 값이 필요함
  - 이 5x5개의 가중치와 1개의 편향 값을 커널, 또는 필터라고 부름
  - 필터는 해당 은닉층을 만들기 위한 모든 윈도우에 공통으로 적용됨

#### 필터 사용의 장점
- 가중치의 수를 줄임으로써 전체 연산량을 대폭 감소시킬 수 있음
- 예를 들어, 입력층의 크기가 28x28 일때 기본 신경망의 경우 28x28=784 개의 가중치를 찾아야 하지만 Convolution Layer 에서는 5x5 개인 25 개의 가중치만 찾으면 됨
- 실질적으로 CNN은 너무 느리기 때문에 사용하기 힘듬

#### 필터 사용의 단점
- 복잡한 특징을 가진 이미지의 분석이 어려움
- 보완책으로서 여러 개의 필터를 사용하며, 분석하고자 하는 내용에 따라 필터의 개수를 어떻게 정하는가 하는 것이 중요함


### Convolution Layer 와 Pooling Layer 의 관계 및 역할
- 이미지 데이터, 즉 2 차원의 평면 행렬에서 지정한 영역의 값들을 하나의 값으로 압축
- 압축할 때
  - Convolution Layer: 가중치와 편향을 적용
  - Pooling Layer: 값들 중 하나를 선택해서 가져오는 역할

![image](https://github.com/user-attachments/assets/632e9851-10d8-4d2e-b194-aad51e01309c)


### 국소 콘트라스트(대비) 정규화
- 자연물 이미지 등 주변의 조명, 카메라의 노출 등 환경 변화에 따라 이미지 전체의 밝기, 대비가 크게 변하는 경우 사용함

- 이미지 밝기 정규화의 방법

- 이미지의 집합(훈련 데이터)에 대한 통계치를 이용하여 이미지의 명암을 전체적으로 조절
  - LCN
  - 이미지 한 장, 한 장에 대하여 개별적으로 조절
  - 고정된 가중치를 사용하므로 학습 가능한 파라미터는 없음


Fully Connected Layer (완전연결층)
- 활용도
- 일반적으로 기존의 신경망에서 각 층별 연결에 사용되는 방식. 전결합층
- 모든 노드를 연결하므로 수많은 연산이 일어남
- CNN 의 특징은 모든 노드를 결합하지 않음으로써 연산량을 줄여 효율성을 높이는 방식
- 그럼 왜 사용하는가?
  - 모든 노드를 연결하므로 1차원배열로 표시됨 ➜ 이미지의 공간정보가 사라짐
  - 최종 결과값은 분류 결과 도출 → 결국 마지막에 도출된 분류결과 Label을 선택하여야 함
  - 최종 결과를 분류하기 위한 기반 정보는 모두 가지고 있어야 분류를 위한 SoftMax 함수를 사용할 수 있음
- 필수는 아니며 Convolution Layer 의 결과를 그대로 사용할 수도 있음

### SoftMax
- 활성화 함수
  - 실제 신경망에서는 우리 몸에서 반응할 필요가 있는 수준 까지만 신호를 전달하고 나머지의 신호는 무시 → 비선형적 특징
  - 합성곱 연산은 입력과 가중치로 이루어진 연산 → 선형성을 가짐 → 비선형 특성 부여를 위하여 활성화 함 수가 필요함
  - 최근 많이 사용되는 활성화 함수는 ReLU(Rectified Linear Unit) 계열의 함수

![image](https://github.com/user-attachments/assets/f8e2a1a8-b888-43bd-849f-f5b1fd8339ff)

### CNN 전체 구조의 예시

![image](https://github.com/user-attachments/assets/59728742-be4c-4129-968b-c6a8a1914538)

## 뇌의 시각정보 처리 구조 : 눈과 망막의 구조

![image](https://github.com/user-attachments/assets/755cee18-2fc9-49fc-a7a1-f637db33cb75)

![image](https://github.com/user-attachments/assets/1724fc62-2d92-4122-b0ca-e247dbd09e48)

![image](https://github.com/user-attachments/assets/54054bb4-e745-45c5-85a3-835bcc2bd6a3)
- 각 원추세포마다 다른 광색소를 함유하기 때문에 인식하는 색이 다름(얼마나 골고루 분포하냐에 따라 색을 잘 구분?)
![image](https://github.com/user-attachments/assets/28280fc4-f65a-4667-a2d7-d27a2b1c7c62)

### 시각 피질
- 안구에서 신경절 세포는 마지막 출력에 해당하는 영역, 뉴런과 동일한 방식으로 동작함
- 망막에서 전기신호로 변환된 시각 정보는 신경절 세포의 반응률에 영향을 미침
- 신경절 세포의 반응률에 영향을 미치는 망막 표면의 영역을 해당 세포의 수용야(Receptive Field) 라고 하며 “ 중심흥분+ 주변억제” 와 “ 중심억제+ 주변흥분” 의 두 가지 형태가 존재함

![image](https://github.com/user-attachments/assets/b4d268e5-314d-4835-8bb2-3ae87a8d0ec5)

#### 시각 피질에서의 시각 정보 처리
- 1 차 시각피질의 세포들
  - 단순세포: 국소적인 영역을 보고, 단순한 패턴에 자극을 받는 세포
    - → 점, 막대, 모서리 같은 사물 형태의 윤곽 일부를 처리
  - 복합세포: 넓은 영역을 보고, 복잡한 패턴에 자극을 받는 세포 → 막대 형태의 움직임 처리
  - 초복합세포: 각진 부분(모서리)의 움직임 처리
- 각 세포들은 수직으로 세워놓은 기둥 형태로 조직되어 있음( 시각피질에서만 이런 형태)
- 각 세포들은 서로 다른 방향의 자극에 대해 반응함
  - 시각피질에서 이러한 기둥 조직에 의해 방향성 정보를 부호화 하는 것이 시각적 공간을 뉴런에 의해서 재구성하는데 매우 중요한 역할을 하는 것으로 추정됨
  - 세포기둥은 세포들의 단순한 집합이 아니라 역동적 기능 단위이다

- 단순세포: 엄격한 위치 선택성을 가짐 (정확한 입력패턴에 반응)
- 복합세포: 입력패턴을 조금 벗어나도 반응함
- 단순세포와 복합세포의 반응성을 모형화

![image](https://github.com/user-attachments/assets/42bd585c-d303-4b07-9259-70febd8b3456)

## CNN 모델의 구상

- 눈과 시각피질 사이의 시각정보 처리 방식에서 개념 도입
  - 망막에서의 빛 인식 영역 → 입력층
  - 시각피질의 단순세포에 의한 입력패턴 대응 영역 → 중간층
  - 시각피질의 복합세포에 의한 활성화 및 차원축소 영역 → 출력층
  - 해당 영역에 대한 수용야(감수영역이라고도 함) → 필터
  - 수용야의 영역 크기 → 윈도우
  - 수용야의 이동 범위 → 스트라이드
  - 수용야의 영역 처리 → 패딩
- 시각 처리 신경망은 단순세포와 복잡세포가 층을 이루어 구성되었고, 층간 연산에 따라 동작 하는 것으로 관찰되고 있으며, CNN 모델은 이를 반영하고 있음

### 시각의 전달 경로
![image](https://github.com/user-attachments/assets/3b78409d-955e-4376-88a6-f97b33a928f5)


### CNN 모델과 DNN 모델의 차이

- CNN 모델과 DNN 모델은 기본적으로 같다
  - 동일한 학습 방법을 따름
    - 모든 층에 대하여 추측을 할 때는 Forward Propagation 수행
    - 모든 층에 대한 가중치(Weight)를 훈련할 때는 Back Propagation 수행
- 차이
  - DNN 모델
    - 목적: 입력에 대하여 원하는 결과가 나올 수 있도록 가중치를 갱신(훈련, 학습)하는 것
    - 학습: 각 노드에 대한 가중치를 학습함
  - CNN 모델
    - 목적: 합성곱(Convolution) 층을 이용하여 유의미한 특징(Feature)을 추출하여 이용하는 것
    - 학습: 각 특징에 대한 가중치를 학습함

### 이미지에서 필터의 특징을 가진 영역을 추출(인식)

![image](https://github.com/user-attachments/assets/b8cefcf5-fd11-42e8-b6cf-9eae141ca466)

- 필터A: 수직의 edge를 검출하는 필터 → 보다 큰 값이 있는 위치에 수직의 edge가 있다는 것을 의미함
- 각 층에서 Back Propagation을 수행할 때
  - 예측 값과 실제 값을 비교한 오차를 정의(계산)한 후, 각 edge의 가중치를 갱신함
 
- 합성곱 층(Convolution Layer)에서의 연산과 DNN 모델에서의 연산의 차이
  - 기본적으로 가중치가 고정되어 있음 (같은 필터를 이미지 전체에 적용하기 때문)
  - 전 결합(Fully Connected) 그래프가 아님
    - 필터를 이미지 전체에 적용하는 것이 아니기때문에
    - 어느 픽셀이 어느 출력 픽셀에 영향을 주는지 추적해야 함   
  - 즉 모델의 각 노드에서 적용되는 필터에 따른 가중치의 연산과 갱신이 이루어짐
 

### CNN 모델
- 데이터로부터 직접 특징을 학습 → 더 복잡한 패턴 학습 가능, 다양한 문제에 더 유연하게 적용 가능
- 이미지의 공간 구조를 인식하고 학습할 수 있음
- 파라미터 공유로 인해 효율적인 학습이 가능함

### 영상 분류
- 주어진 이미지가 어떤 카테고리에 속하는지 판단하는 과정
- 이미지 전체를 한 카테고리로 분류

- 영상 분류에서는 이미지 전체를 분석하여 하나의 레이블로 분류함
- 일반적인 CNN 구조가 사용됨
- 마지막 출력 층에서 소프트맥스 활성화 함수 등을 사용하여 카테고리별 확률을 계산함


### 영상 검출
![image](https://github.com/user-attachments/assets/18edd3d4-7fd2-4570-a169-8840e7863a77)

- 주어진 이미지에서 어떤 객체가 어떤 위치에 존재하는지를 파악하여 해당 영역의 카테고리를 할당하는 작업

- 이미지 내 객체의 위치와 카테고리를 동시에 찾음

- 검출은 이미지 내의 여러 객체를 찾아야 하므로, 로컬 영역에서의 패턴을 파악해야 함
- YOLO, SSD와 같은 특수한 구조를 사용하여 객체의 경계 상자와 함께 클래스 레이블을 예측

### 영상 영역 분할

![image](https://github.com/user-attachments/assets/a086b999-51d7-4068-9fa5-042993a42a61)

- 이미지의 각 픽셀이 어떤 카테고리에 속하는지 판단하는 작업
- 이미지의 각 픽셀 별로 카테고리 할당

- 이미지의 각 픽셀에 레이블을 할당해야 하므로, 공간 정보를 잘 보존해야 함
- U-Net과 같은 구조가 사용됨
- 업샘플링과 다운샘플링을 통해 고해상도의 세그멘테이션 맵을 생성함

### 영상 복원
- 영상 복원은 손상된 또는 왜곡된 이미지를 복원하는 작업
  - 노이즈 제거, 해상도 향상 등
- 손상된 이미지 복원

- 원래 이미지의 특성을 복구해야 하므로, 손실함수와 네트워크 구조가 복잡할 수 있음
- SRCNN, GAN(생성형 ai 초기형태를 이용한 모델) 등의 고급 기술을 사용하여 이미지의 본래 특성을 복원함


![image](https://github.com/user-attachments/assets/b1bac4e0-75d6-4274-9a25-fb66b03541ce)
- Super Resolution

![image](https://github.com/user-attachments/assets/78297f5f-743a-431f-8dd2-b055219cc0cc)
- 비어있는 부분을 유사한 형태로 복원, 컬러화

![image](https://github.com/user-attachments/assets/5a3f1a2a-e17c-4674-bfc3-f64568e52ba7)
- 합성, 열화 문제 해결

![image](https://github.com/user-attachments/assets/c34206ef-1c27-4322-8eed-fa205fabcee9)
- 고해상도 변환

------------------
## 실습

### 2024.10.02_pytorch_cnn.ipynb
#### 합성곱 신경망(CNN) 구성:
- torch.nn.Conv2d와 torch.nn.MaxPool2d를 사용하여 CNN의 기본 블록(Convolution Layer, Pooling Layer) 구성.
- 다양한 필터 크기와 채널 수를 조정하여 이미지 분류 및 처리 모델을 구축.

#### 모델 학습 및 테스트:
- CNN을 사용한 이미지 분류 모델을 학습시키고, 학습 후 테스트 데이터셋에 대한 성능 평가.
- torchvision 라이브러리를 사용하여 데이터셋 로드 및 전처리.

#### 요약
- CNN의 기본 개념과 PyTorch를 사용하여 CNN 모델 구성 및 학습.
- 이미지 분류 모델을 구축하고, 성능 평가 및 결과 시각화.

### 2024_10_02_Tenserflow.ipynb , 2024_10_02_Tenserflow_2.ipynb
#### 고급 신경망 모델 구성 및 학습:
- 텐서플로우에서 심층 신경망 모델, RNN 또는 LSTM 등의 순환 신경망(Recurrent Neural Network) 구현.
- 자연어 처리(NLP) 또는 시계열 데이터 예제를 사용하여 RNN, LSTM 모델 학습.

#### 전이 학습(Transfer Learning):
- 사전 학습된 모델(Pre-trained Model)을 사용하여 새로운 데이터셋에 맞춰 추가 학습.
- tf.keras.applications을 사용하여 다양한 사전 학습된 모델 불러오기 및 fine-tuning.

#### 요약
- TensorFlow에서 RNN, LSTM 또는 전이 학습과 같은 고급 모델 구현.
- 고급 신경망 구조의 학습, 평가 및 전이 학습 방법.

--------------
- 오늘 학습한 실습 내용은 아래 주소에 2024.10.02 날짜 파일들로 정리함
- https://github.com/Astero0803/Machine-Learning-Frameworks-/tree/main

## 백준
- 3009번 : 네 번째 점
- 해당 문제는 3개의 좌표가 주어졌을 때, 직사각형을 만들기 위한 나머지 한개의 좌표를 구하는 문제였다.

### 접근 방법
- 직사각형은 내각이 모두 직각이며 마주보는 두 변이 평행하기 때문에, 3개의 좌표가 주어질 경우, 쉽게 나머지 좌표를 구할 수 있다 판단했다.
- x축과 평행하는 두 변에서, 왼쪽에 위치한 두 좌표의 x 좌표는 서로 같고, 오른쪽에 위치한 두 좌표의 x 좌표는 동일
  - => x 좌표의 개수는 2개
- y축과 평항하는 두 변에서, 위쪽에 위치한 변의 두 좌표의 y 좌표는 서로 같고, 아래에 위치한 변의 두 좌표의 y 좌표는 동일
  - => y 좌표의 개수는 2개
- 이에 x좌표와 y좌표를 넣어줄 빈 리스트 x_ 와 Y_를 선언하고, 3개의 좌표는 해당 문제에서 주어지므로, for문을 통해 3번 반복되도록 하여 x와 y변수에 map함수를 통해 각각 숫자를 할당한 뒤 좌표를 x_리스트, y_리스트에 입력 해주었다.
- 이후 첫 번째 for문이 종결되면, 다시 새로운 for문을 3회 반복하고 각각 리스트 내 숫자가 1개인 인자를 출력하는 것으로 마무리 하였다.
```
x_ = []
y_ = []

for i in range(3):
    x, y = map(int, input().split())
    x_.append(x)
    y_.append(y)

for i in range(3):
    if x_.count(x_[i]) == 1:
        x = x_[i]
    if y_.count(y_[i]) == 1:
        y = y_[i]
print(x,y)
```
