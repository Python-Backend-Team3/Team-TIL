# 📝 2024.10.07 회고 📝
#### 1. 수업 내용 복습정리
#### 2. 백준

---------------------------------

## 자연어 처리 기술

- 현재 일반적인 AI기술은 하나의 개체(인간)이 가지는 생물학적/기계적인 기능을 흉내 낸 것

#### 언어의 등장
- 인간은 사회적인 동물 이다.
  - 인간은 크고 작은 사회, 조직 안에서 지식과 지혜를 세대를 거쳐가며 누적 시킴으로 문명을 이루며 본능과 다른 지성을 성립시켜 옴
  - 이 과정에서 사람 사이의 소통이 요구됨
  - 이 커뮤니케이션을 위해 발생한 언어, 즉 자연어(Natural Language)

#### 자연어의 발생
- 인간이 스스로의 지식을 구조화 할 수 있게 진화 시킴
- 인간의 사고 행위는 언어(자연어)로 구성됨

- 언어의 발생 의의
  - 인간의 진화는 매우 더디게 진화 -> 언어의 발생과 함께 폭발적 진화
  - 언어 발생 이전 사고 -> 단순한 동물이 보이는 기계적 반응에 그침
  - 언어 사용 -> 지식 구조화 성립, 현대적인 의사소통 능력 발생
- 인간의 사고 능력은 생물학적 기능의 모방으로 구현할 수 없으며 사고 능력은 언어를 기반으로 성립함


- 인간의 지능, 지성은 복합적으로 구성됨
- 하나의 개체에만 적용되는 지능, 지성, 사회를 구성하는 집단에서 발생하는 집단 지성
- 이러한 모든것을 연결하는 핵심이 언어(자연어)다.
- 언어를 컴퓨터/AI가 처리할 수 있게 되면서 단순 산업, 계산, 예측을 위한 시스템에 인간이 쌓아 올린 문명과 문화가 반영되기 시작했다.

## 자연어 처리 기술의 개요
- 프로그래밍 언어와 같은 인공적으로 만든 언어가 아닌, 사람이 일상생활과 의사소통에 사용해 온, 한국어, 영어와 같이 오랜 세월 걸쳐 자연적으로 만들어진 언어라는 의미

#### 자연어 처리란?
- 컴퓨터가 인간의 언어를 알아들을 수 있도록 인간의 언어를 분석 해석해 처리하는 인공지능의 분야
- 자연어를 컴퓨터로 해석하고, 의미를 분석해 이해하고, 자동으로 생성하는 것 등에 관련된 분야
- 자연어 처리의 목표는 "어떻게 자연어를 컴퓨터에게 인식시킬 수 있을까?"라는 것

- 자연어에 대한 연구는 오래전부터 이어지고 있음에도 현재까지도 컴퓨터가 자연어를 사람처럼 이해하지 못함
- 언어에 대한 깊은 이해없이는 피상적인 확률 및 통계를 이용하여 대량의 정보를 처리하는 기술은 많이 발전한 상태이다. (검색 엔진: 단어 간 통계적 유사성 바탕으로 문서 검색)

###### 컴퓨터에 일 시키는 과정
- 기존 컴퓨터 기술에서는 컴퓨터에게 일을 시키기 위해 사람이 컴퓨터 언어를 학습했는데, AI기술을 사용하면 컴퓨터에게 일 시키기 위해 컴퓨터가 사람의 언어를 학습(1대1 매칭)
![image](https://github.com/user-attachments/assets/48da3d84-ac04-4bdc-9b60-907baa0d1d67)


#### 자연어 처리에 요하는 기술
- 인공지능 기술
- 컴퓨터 공학 기술
- 언어학적 기술
  - 광범위한 기술 분포로 인해 쉽게 접근하기 어려움
  - 제대로 기술을 익히고자 한다면 연구/개발에 투자하고자 하면 필수이다.

#### 자연어처리 대표적 분야
- 텍스트 분류
- 텍스트 유사도
- 자연어 생성 (-> 텍스트 생성)
- 기계 이해 (-> 텍스트 이해)

- 4대 문제를 이해하려면 먼저 "단어의 표현"에 대해 이해하여야 함
  - 단어의 표현 (모든 자연어 처리 문제의 기본, 자연어를 어떻게 표현할 것인지 결정하는 것이 문제에 대한 해결의 출발점임)

#### 컴퓨터의 텍스트 인식
- 컴퓨터가 인식할 수 있는 것은 전자 소재의 on/off 상태값 뿐이다.
- 사람 기준에 좀 더 보기 쉽게, 산술적(수학적)으로 표현하기 쉽게 하기 위해 0, 1 의 값으로 대체(변환)해서 표현했다.
- 컴퓨터는 자연어를 이해하지 못하며, on/off 2진수 표현을 기반으로 한 수치 데이터만 사용 가능 -> 단어의 수치화가 필요 -> 통계의 사용이 가능해짐 
- 단어의 수치화 결과는 벡터로 표시 -> 단어 임베딩, 단어 벡터 등으로 표현된다.

###### 단어의 수치화를 위한 대표 방법
- 원-핫 인코딩
  - 각 단어에 인덱스 부여해 각 단어의 벡터에서 해당 인덱스를 1, 나머지는 0

![image](https://github.com/user-attachments/assets/bb4d3804-8f6a-4566-98f9-23c0770c0d5f)

- 분포가설 기반의 인코딩
  - 분포가설 : 같은 문맥의 단어, 즉 비슷한 위치에 나오는 단어는 비슷한 의미를 가짐
  - 어떤 글에서 비슷한 위치에 존재하는 단어는 단어 간의 유사도가 높다고 판단
  - 카운트 기반 방법, 예측 방법
 
##### 벡터화 방법의 장단점
- 원-핫 인코딩
  - 간편하고 이해 쉬움
  - 처리할 단어의 수가 많을 수록 벡터의 크기 급증 -> 매우 비효율적(희소벡터)
  - 단어가 무엇인지만 확인 가능해 단어의 의미, 특성, 관계 등의 정보는 표현되지 않음
 
- 분포가설 기반의 인코딩
  - 각 단어 사이 유사도 및 관계성, 특징 등 표현
  - 예측 방법의 경우 성능이 뛰어나므로 가장 많이 활용됨 

##### 분포가설 기반의 인코딩
- 카운트 기반 방법
  - 특정 문맥 안 단어들이 동시에 등장하는 횟수를 직접 세어, 횟수를 행렬로 나타내고, 그 행렬을 수치화해 단어 벡터를 만드는 방법
  - 특이앖 분해, 잠재 의미 분석, Hyperspace Analogue to Language(HAL), Hellinger PCA(Principal Component Analysis, 주성분 분석) 

- 예측 방법 
  - 신경망 또는 통계모델 등을 통해 문맥 안 단어들을 예측하는 방법
  - Word2Vec, NNLM(Neural Network Language Model), RNNLM(Recurrent NNLM)
  - 대표는 Word2Vec(임베딩 모델임)를 이용해 단어를 벡터로 바꿈, Word2Vec은 CBOW, SKip-Gram모델로 구분됨

### 텍스트 분류
##### 텍스트 분류 문제
  - 자연어 처리 문제 중 가장 대표적 문제
  - 자연어 처리 기술을 활용해 특정 텍스트를 사람들이 정한 몇 가지 범주 중 어느 범주에 속하는지 분류하는 문제
  - 스팸 분류, 감정 분류, 뉴스 기사 분류

- 지도학습 을 통한 분류
  - 선형 분류
  - 신경망
  - 나이브 베이즈 분류
  - 서포트 벡터 머신
  - 로지스틱 분류
  - 랜덤 포레스트 등 

![image](https://github.com/user-attachments/assets/f85b5233-034c-47ad-b8b3-bbda1aa318bc)

- 비지도학습을 통한 분류 (알고리즘 만들고하는 과정은 없고, 데이터 특성이 비슷한거끼리 모음)
  - k-평균 군집화
  - 계층적 군집화

![image](https://github.com/user-attachments/assets/6a71a04f-390b-4a71-9555-9113c9229f51)


##### 텍스트 유사도
- 텍스트가 얼마나 유사한지 표현하는 방법
- 이 노래 누가 만들었어?, 지금 나오는 노래 작곡가가 누구야? 이런거
- 예시 같은 두 문장이 얼마나 유사한지 정량화 해 수치로 표현하는 모델을 만드는 것이 중요함

- 유사도 측정을 위한 정량화 방법
  - 같은 단어의 개수를 사용하여 판단하는 방법(카운팅)
  - 형태소로 나눠 형태소 비교를 하는 방법
  - 문장, 단어를 자소 단위로 나눠 각 단어를 비교하는 방법
  - 딥러닝 기반으로 측정하는 방법

- 많이 사용되는 유사도 측정 방법
  -  자카드 유사도, 유클리디언 유사도, 맨해튼 유사도, 코사인 유사도  

### 자연어 생성
- 자연어 생성, 텍스트 생성, 문장 생성 등으로 표현
- 뉴스 기사 생성, 대화 생성, 챗봇 등 다양한 영역에서 활용
- 인간과 컴퓨터 사이의 의사소통을 위한 가장 자연스로운 방식
- 언어모델 기반(최근), 패턴 기반(예전)의 자연어 생성 으로 형태를 나눠서 생각할 수 있다.

- 언어 모델을 이용한 방식
  - OpenAI의 GPT, Naver의 HyperClova 등 다양한 언어 모델 존재
  - 수많은 데이터의 학습을 통해 어떤 표현이 가장 적절한지 예측하여 문장 생성
    - GPT3는 약 1750억개의 파라미터 데이터를 이용해 학습을 진행   

- 언어 모델을 이용한 방식의 문제점
  - 가장 자연스로운 문장을 만드는 것에 강점을 가짐
  - 어떤 데이터를 기반으로 정확한 사실을 전달하는 문장을 만들지 못함
  - 뉴스 기사를 언어모델로 작성하면, 사람이 쓴 것같은 자연스로운 기사를 쓸 수 있지만 데이터 기반으로 하지 않기 때문에 가짜 뉴스가 만들어짐

- 패턴 기반의 방식의 문제점

### 기계 이해 (-> 텍스트 이해)

- QNA문제
- 기계까 텍스트를 이해하고 논리적으로 추론을 할 수 있는지를 데이터 학습을 통해 구현, 확인하는 것
- 앞서 설명한 텍스트 분류, 유사도, 자연어 생성 등 자연어 처리에 대한 전반적인 내용이 모두 포함되어 있다 볼 수 있음

- 자연어 처리의 활용 분야
  - 대량의 텍스트를 이해하고 수치화 하는 분야
    - 감성분석, 문서분류, 문서요약
  - 사용자 의도를 파악하고 대화하거나 도움을 주는 분야
  -   AI 스피커, 
   

### 딥러닝 적용 이전의 자연어 처리 방식

![image](https://github.com/user-attachments/assets/07307353-5cb2-4076-84d0-caec90ec46df)

### 자연어 처리(분석중심)의 일반적인 단계

![image](https://github.com/user-attachments/assets/b00eca9d-b580-4f24-83a6-3e640b9cedbd)

### 어휘 분석
- 기술 구성
  - Sentence Splitting : 마침표, 느낌표, 물음표 등을 기준으로 분리
  - Tokenizing : 문서나 문장을 분석하기 좋도록 나눔(띄어쓰기 또는 형태소 단위)
  - Morphological : 토큰들을 좀 더 일반적인 형태로 분석해 단어 수를 줄임으로 분석의 효율성을 높임(가장 작은 의미 단위로 토큰화 진행)
  - Stemming(어간추출, 형태소 분석) : cars, car -> car
  - = Lemmatization : 단어를 원형으로 표현
- 필요성 : 입력된 문장을 잘 분할해서 효율성을 높이기 위함


#### 구문분석(Syntax Analysis)
- 각각의 어절 단위로 구분, 해당 태그 부여(Parsing Tree 이용)

#### Semantic Analysis (의미분석)
- Syntactic + Meaning
- 문장의 의미에 근거해서 그 문장을 해석하는 방법
- 여러의미 분석 방법과 다양한 유형의 문법 이용
- 문장이 어떻게 구성되었는지 나타내는 규칙들로 구성된 일종의 형식 시스템
- 필요성
  - 규칙에 따라 문장은 만들었는데, 문장이 의미적으로 올바른 것인지 확인해야 함

#### 실용분석 Pragmatic Analysis
- 실용주의
  - 인간의 행동과 실제적 측면에 대한 연구
  - 실제 상황에서의 언어, 표시, 단어 및 문장의 사용에 대한 연구
- 실용적인 상호 작용 컨텍스트(문맥, 맥락)에서 의미 연구 가리킴
 - 발언의 문자적 의미 넘어 그 의미가 어떻게 구성되는지 대한 것만 아닌 묵시적 의미에 초점(상호작용의 도구로 언어 선택)

- 실용주의 관점에서 고려할 사항
  - 연사와 청취자 사이 의미 전달, 협상
  - 발언에 대한 맥락
  - 발언이 가지는 의미 및 의미에 대한 잠재력
 
- 필요성 : 대화 흐름을 파악해 발화자 의도에 맞도록 응답

























```











