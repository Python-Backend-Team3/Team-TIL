# 2024-10-02 회고
### 회고 목표: DNN,CNN 모델 내용 정리하기

딥러닝 모델에서 기본적 모델인 DNN에 대해 정리해보려 한다.

- Batch size: 한번에 학습할 데이터의 수
  - 클수록 빠르지만 성능 저하
  - 작을수록 느리지만 성능 향상
  - 속도와 성능 사이의 trade-off가 존재
- epochs: 전체 데이터를 반복적으로 학습하는 횟수
  - 너무 크면 과적합 발생

![image](https://github.com/user-attachments/assets/acb24e41-5601-4e06-b33f-fc38fb40db2e)

전체 데이터 2000개, Batch size를 200으로 iteration을 10번 돌리면

전체 데이터를 1번씩 모두 학습한 것이므로 epoch 한 번을 돌렸다고 할 수 있음

epoch에 따라 training set과 validation set의 loss가 달라지는데,

training set은 epoch가 반복될수록 loss가 점점 줄어드는 걸 볼 수 있다
(하지만 단순히 loss가 줄었다고 해서 좋은 모델인 것은 아님,overfitting 가능성이 높기 때문)

따라서 가장 최고의 모델은 training set으로 훈련한 모델의 validation set에서 가장 적은 loss를 가지는 지점의 모델이다.

## DNN(Deep Neural Network)

![image](https://github.com/user-attachments/assets/621d20f8-6de7-4be6-9441-dd43f1e2aaf0)

### 특징
- 입력층과 출력층 사이에 여러 개의 은닉층들로 이루어진 인공 신경망
- 고차원의 데이터(이미지, 음성, 텍스트)를 그대로 사용하더라도 자동으로 feature를 정의할 수 있는 장점
- 기존의 머신러닝 에 비해 우수한 예측 정확도를 가짐
- 특정 분야에서 인간의 능력보다 우수한 성능을 보임

![image](https://github.com/user-attachments/assets/2093bdb0-760c-49ab-9196-3f681064330d)

- 특정 데이터에서 학습된 구조를 다른 데이터(도메인)에서도 사용가능한 장점(전이학습, Transfer Learning)

### 문제점1
하지만 **sigmoid 함수**를 사용하면 hidden layer의 수가 증가함에 따라 하위 층으로 갈수록 gradient가 0이 될 가능성이 높아져서
**Backpropagation**이 진행되지 않음

![image](https://github.com/user-attachments/assets/01e7ab4c-b5bb-48c7-889f-aeb4ccf22142)

즉 기울기 소실 문제가 발생

### 해결 방법1
이를 해결하기 위해 **ReLU 함수** 사용

### 문제점2
그러나 **overfitting** 문제가 발생할 수 있음

![image](https://github.com/user-attachments/assets/fbcfee9c-334f-4e74-b8e8-e2a32e21cbb8)

### 해결 방법2
**Drop-Out**방식을 사용하여 학습 과정에서 일부러 특정 노드들에 연결된 가중치들은 업데이트 하지 않고

어떤 노드를 업데이트 시키지 않을 것인지 무작위로 결정하여 모델이 하나의 data set에 overfitting하는 것을 방지

또는 
**Data Augmentation** 방법을 사용

모델의 파라미터의 수가 엄청나게 많은데, 보유하고 있는 데이터의 수는 너무 적어 overfitting이 발생하므로

현재 보유한 데이터를 증폭해서 학습시키도록 함

아래 사진처럼 하나의 데이터를 증폭하여 여러 가지의 데이터로 만들어 학습 시키면 과적합도 방지하고 정확도도 올릴 수 있음

![image](https://github.com/user-attachments/assets/80ad5874-6fab-480e-b32f-566d10e45c73)

텍스트 데이터도 가능함

![image](https://github.com/user-attachments/assets/f23a9ec7-c219-4ca3-8906-ec5df234537a)


## CNN(Convolutional Neural Network)
- 합성곱 신경망, 이미지의 공간 정보를 유지한 상태로 학습이 가능한 모델
- vision 분야에서 성능이 우수
- 이미지를 인식하기 위해 패턴을 찾는데 특히 유용
- 데이터를 직접 학습하고 패턴을 사용해 이미지를 분류함
- 자율주행자동차, 얼굴인식 등에 사용되고 있음

### CNN 구조
![image](https://github.com/user-attachments/assets/28676b20-f213-40d5-b205-2457ea459a54)

이미지의 특징을 추출하는 부분과 클래스를 분류하는 부분으로 나눌 수 있음

Feature extraction/learning 영역은 **Convolution Layer와 Pooling Layer**를 여러 겹 쌓는 형태로 구성된다

Convolution Layer는 입력 데이터에 필터를 적용 후 활성화 함수를 반영하는 필수 요소임
Pooling Layer는 선택적 레이어

CNN 마지막 부분에는 이미지 분류를 위한 **Fully Connected Layer**가 추가됨
이미지의 특징을 추출하는 부분과 이미지를 분류하는 부분 사이에 이미지 형태의 데잍터를 배열 형태로 만드는 Flatten Layer가 위치함

### Convolution Layer
이미지 데이터는 아래 그림과 같이 높이 * 너비 * 채널의 3차원 tensor로 표현 가능함
만약 이미지의 색상이 RGB 코드로 표현되었다면 채널의 크기는 3이 되고 각각의 채널에는 R,G,B값이 저장됨

#### 컬러 이미지는 3D
![image](https://github.com/user-attachments/assets/0dcc484c-2f63-4632-a2eb-4ae6da7e83c8)


#### 필터 적용
하나의 합성곱 계층에는 입력되는 이미지의 채널 개수만큼 필터가 존재하며, 각 채널에 할당된 필터를 적용함으로써 합성곱 계층의 출력 이미지가 생성됨

![image](https://github.com/user-attachments/assets/865b2962-742a-4a84-9229-068f5acad197)

실제 구현에서는 합성곱을 통해 생성된 행렬 형태의 이미지에 bias 스칼라값을 동일하게 더하도록 구현되기도 함

#### Stride
이미지에 대해 필터를 적용할 떄 필터의 이동량을 의미하는 Stride를 설정해야 함

![image](https://github.com/user-attachments/assets/bfdd5162-c27c-43ed-9ad6-247a2641c01c)

주로 1로 설정함

#### Padding

- 입력 이미지에 대한 합성곱을 수행하면 출력 이미지의 크기는 입력 이미지의 크기보다 작아짐
- 따라서 합성곱 계층을 거치면서 이미지의 크기는 점점 작아지게 되고,
- 이미지의 가장자리에 위치한 픽셀들의 정보는 사라지므로 이러한 문제를 해결하기 위해 패딩을 함

![image](https://github.com/user-attachments/assets/e0d8dd30-eb78-47f9-bc8a-b788ebcf68ba)

입력 이미지의 가장자리에 특정 값으로 설정된 픽셀을 추가하여 입력 이미지와 출력이미지의 크기가 같거나 비슷하게 만드는 역할을 함

### Pooling Layer
이미지의 크기를 계속 유지한 채 Fully Connected layer로 가게 되면 연산량이 기하급수적으로 늘 것임
적당히 크기도 줄이고, 특정 featuer를 강조할 수 있어야 하는데 그 역할을 Pooling Layer에서 함

- Max Pooling : 주로 사용함
- Average Pooling
- Min Pooling

![image](https://github.com/user-attachments/assets/abf8d26b-96c9-475c-97ad-def5f4e2c77a)

### Fully Connected Layer
지금까지는 특징 추출을 위한 작업.
이제는 분류 작업을 해야함

- Flatten Layer: 데이터 타입을 Fully Connected 네트워크 형태로 변경
- Softmax Layer: Classification 수행

**CNN은 Convolution 과 Pooling을 반복적으로 사용하면서 불변하는 특징을 찾고, 그 특징을 입력데이터로 Fully-connected신경망에 보내 Classification을 수행하는 것**



