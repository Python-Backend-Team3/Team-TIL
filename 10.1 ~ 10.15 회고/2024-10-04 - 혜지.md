# 🎈 10월 4일 회고
# 🎉 YOLO(You Only Look Once) 모델

## 1. YOLO 모델
### 1-1. 개요
- **이미지를 한번만 보고 바로 물체를 검출하는 딥러닝 기술을 이용**한 물체 검출 모델
- 이미지나 영상 한번만 보고 바로 물체 검출을 하기 때문에 이미지에 대해 빠른 속도로 검출이 가능
![image](https://github.com/user-attachments/assets/3fb5005c-ab12-4913-a3a6-3bd0c4f8dda9)

![image](https://github.com/user-attachments/assets/5d28e52c-bf60-4c22-9a70-8503e494d0b8)
<br><br/>
### 1-2. 경계박스를 찾는 법
![image](https://github.com/user-attachments/assets/93b6a410-613b-43de-8d37-eaff294fce88)

![image](https://github.com/user-attachments/assets/0bbe1f70-6a81-42cb-ac00-0b17b71f62d9)

- Grid 방식이 후보 영역 제안 개수가 적고 실시간성 확보가 용이하기 때문에 Grid 방식을 발전시켜서 사용
- 최종 출력단에서 경계박스 검색과 클래스 분류를 동시에 수행하기 때문에 속도가 빠름
- 하나의 네트워크가 동시에 특징을 추출하고 경계박스를 만들고 클래스 분류를 다 하기 때문에 구조가 간단하고 빠름
<br><br/>

## 2. 네트워크 구조
![image](https://github.com/user-attachments/assets/85adf1f5-f71e-43e4-9ab6-58dd258c91aa)
<br><br/>

## 3. 최종 결과
![image](https://github.com/user-attachments/assets/402c5840-263a-4469-8f0c-e43c6a573db3)

![image](https://github.com/user-attachments/assets/241ecaf3-57e8-4b54-b5e1-108eafeaac00)

![image](https://github.com/user-attachments/assets/99ccbf7c-2738-4660-a44a-e9a2671c0875)

![image](https://github.com/user-attachments/assets/ba23825f-3520-45b8-9018-2fd98e54a0d3)

![image](https://github.com/user-attachments/assets/361103dd-e738-462e-b850-23fce755b830)

![image](https://github.com/user-attachments/assets/109dc97d-fcb5-4277-8056-465c26331ea3)

![image](https://github.com/user-attachments/assets/cb99713f-141f-47d7-890e-658ec526d9c3)

![image](https://github.com/user-attachments/assets/ffb6b5e3-1c3d-4215-a235-71b06e6df251)

![image](https://github.com/user-attachments/assets/6f75c660-5864-4daa-944a-50e3af3a3da4)


<출처: https://brunch.co.kr/@aischool/11 >
<br><br/>

# 📑 데이터 라벨링
## 데이터 라벨링(Data Labeling)

### 1-1. 개요
- 딥러닝에서 가장 중요한 것은 데이터임 (특히 학습을 위한 데이터가 중요)
- 딥러닝 모델은 학습의 결과가 옮은지, 그른지 확인할 수 있도록 각각의 영역을 구분하고 표시해두는데 이를 데이터 라벨링이라 함

### 1-2. 라벨링 작업에 대한 사전 고려사항
**① 라벨링 영역의 지정에 대한 규칙 필요 (정확한 수치 규정일 필요 X, 대략적인 느낌을 통해 적용함)**
- 인식하고자 하는 대상과의 거리
- 시선의 초첨으로부터 허용되는 좌우 및 상하 범위(각도)
- 인식 대상에 대한 선명도(흐릿함)의 허용 범위
- 인식 대상에 적용되는 밝기의 허용 범위
- 인식 대상의 크기는 다양하게 적용 가능하도록 이미지 선택

![image](https://github.com/user-attachments/assets/557cd35b-5ec0-425e-b80a-c8128dbb7869)

![image](https://github.com/user-attachments/assets/4944a1cc-55a5-41fe-a381-a01aea2db073)

![image](https://github.com/user-attachments/assets/9a21a96f-cfe4-4381-aa0f-041dea0d470e)

![image](https://github.com/user-attachments/assets/88d23783-5185-4eea-b4c2-1a48d67d0da4)

**② 영상의 전처리 범위에 대한 규칙 필요**
- 입력 영상의 주변 환경 (실내, 실외, 맑음, 흐림 등)을 기준으로 입력 영상에 대한 표준 밝기
- 입력 영상의 해상도를 기준으로 하는 이미지의 표준 크기
- 그 외, 특정 환경에서의 인식이 필요한 경우, 해당 환경에 맞는 밝기, 크기 등의 사전 규칙 결정
<br><br/>

# 🗃️ RNN((Recurrent Neural Network) 모델
## 1. 시계열 데이터 (Time Series Data)
### 1-1. 개요
- 시간의 순서대로 일정한 주기에 따라 측정, 저장된 데이터
- 활용 분야
  - 데이터를 기반으로 한 예측 분야에 가장 많이 활용됨
  - 간혹 장애 검출에도 활용할 수 있다고 이야기하고 있으나 결국 데이터 기반 예측임
    - 입력 데이터를 순서대로 살펴보면 조금씩 어긋나는 데이터 발견 가능
    - 어긋나는 데이터의 범위가 특정 기준을 벗어나는 시점이 장애 발생 시점
    - 데이터의 변동을 기반으로 분석, 예측한 결과를 장애 검출, 장애 예측으로 표현하는 것뿐
  - 시계열 데이터는 **시간에 따른 변화를 보고 패턴을 분석하여 이후에 어떤 데이터를 얻을 것인지 예측하는 것이 가장 큰 목적이자 활용분야**

### 1-2. 구성과 처리방식

#### 구성 원리
- 시간의 흐름에 따른 데이터는 주변 환경과 특정 이벤트로부터 많은 영향을 받기 때문에 단순히 데이터의 변화 패턴을 분석하는 것만으로는 예측이 어려움
- 어떤 값과 어떤 변수를 중심으로 분석하는가에 따라서도 큰 성능변화, 결과의 차이 발생
  
![image](https://github.com/user-attachments/assets/eb0f1e08-bb41-4425-950e-d926ef9ea5ce)

#### 시계열 데이터를 이용한 예측
- 현재(t(0))의 데이터는 과거(t(-m) ~ t(-1))의 데이터가 누적된 결과
- 가장 가까운 미래(t(1))의 데이터는 과거와 현재(t(-m) ~ t(-1) + t(0))의 데이터가 누적된 결과
- 미래(t(n))의 데이터는 (t(-m) ~ t(0) ~ t(n-1)) 의 데이터가 누적된 결과
- 여기에 각 시점에서 적용되는 특정이벤트(외부요인)의 반영으로 예측
  
![image](https://github.com/user-attachments/assets/e08fe142-0645-4cdf-aaf9-6e617873ce60)

### 1-3. 모델 제안

#### 1단계
- 과거의 데이터가 현재, 미래의 데이터에 영향을 미치기 때문에 **과거의 데이터를 가지고 와서 현재, 미래의 데이터에 적용시켜야 함**
- 과거의 데이터를 기억하고 있어야하므로 **과거 데이터를 저장, 참조할 수 있는 메모리 효과를 가진 모델이 필요**
  
#### 2단계
- 현재의 데이터를 확인하기 위하여 알고자 하는 시점의 데이터를 기준으로 과거의 데이터를 순차적으로 살펴보는 것이 필요
- 즉, **동일한 과정, 모델이 계속적으로 반복되는 순환 과정을 가진 모델 필요**
- **순환신경망 (RNN, Recurrent Neural Network) 제안됨**
<br><br/>

## 2. RNN 모델의 구조와 이해
### 2-1. 기존의 신경망
![image](https://github.com/user-attachments/assets/9e65903a-11c2-4ff0-a621-d699ae72cc41)

#### 단점
- 한 방향으로만 데이터를 처리하므로 시계열 데이터의 처리가 어려움
- 시계열 데이터는 신경망의 학습이 완료된 후에도 실제 사용 도중에 지속적으로 과거의 데이터를 참조하고 활용하여야 함
- 학습 과정에서도 시계열 데이터의 성질, 패턴을 제대로 학습할 수 없음

### 2-2. RNN (Recurrent Neural Network, 순환 신경망) 개요
- 전체 네트워크 안에서 순환적으로 데이터를 처리하는 신경망 모델
- 시간의 흐름에 따라 과거의 데이터의 특징과 패턴을 반영하여 현재의 데이터를 학습하는 모델
- 순차열, 즉 **순서가 있는 일련의 값을 처리하는 것에 특화된 모델**
- 순환 처리를 하기 위해서는 닫힌 경로(=순환하는 경로)가 필수
- 경로가 닫혀 있기 때문에 데이터가 순환하고, 데이터의 저장이 가능하며, 순환하기 때문에 끊임없이 데이터가 갱신됨

### 2-3. RNN 모델의 기본 원리
ⓛ RNN의 기본 단위 : RNN 계층
- 순환 경로를 포함함
- 계속적인 참조가 반영됨
- 과거의 정보를 기억함
  
![image](https://github.com/user-attachments/assets/cdeb3e91-7bff-4b2e-be81-7362f216b36c)
    
![image](https://github.com/user-attachments/assets/0718c188-590b-4318-a82d-2b6f9719100c)

![image](https://github.com/user-attachments/assets/57c97a9c-bc42-48e9-81e7-a6c3a9e94827)

![image](https://github.com/user-attachments/assets/2c9f56a8-6971-462a-a2a9-789f7df1a23c)

![image](https://github.com/user-attachments/assets/85fe9c3f-f881-4de3-8a99-1b16fd532866)

![image](https://github.com/user-attachments/assets/4b56a8e5-52ac-4d0c-acb4-370dc1709548)

② BPTT (Back Propagation Through Time)의 문제점
- 긴 시계열 데이터를 학습할 때 문제가 생김
  - 시계열 데이터의 시간 크기가 커질수록 BPTT가 소비하는 컴퓨팅 자원도 비례하여 증가함
  - 시간의 크기가 커질수록 역 전파 시의 비율 조정을 위한 기울기가 불안정해짐
    
![image](https://github.com/user-attachments/assets/1bb57f30-91fe-4b40-bfd8-8bfbe01d5823)

③ Truncated BPTT
- BPTT 개선을 위해 제안된 기법
- 시간축의 방향으로 길어진 신경망을 적당한 지점에서 잘라내어 여러 개의 작은 신경망으로 만듦
- 잘라낸 작은 신경망에서 BPTT를 수행함
- 주의점
  - 신경망을 잘라낼 때 역전파의 연결만 절단해야 함 (순전파의 연결은 반드시 유지)
  - 순전파의 연결이 사라지면 네트워크 자체가 성립되지 않음
- 역전파가 연결된 RNN 계층의 모임을 블록이라고 하여 다른 블록과 구분하여 처리함
  
![image](https://github.com/user-attachments/assets/fd443369-c6f3-4209-85ee-7cde86dbc506)

### 2-4. RNN 모델의 문제점
- 시계열 데이터의 학습에서 장기 의존 관계의 학습이 어렵다
  - BPTT에서 기울기 소실 또는 기울기 폭발 발생
    - 기울기 소실: 역 전파 처리 시 기울기 값이 점점 작아지다가 사라지는 현상
    - 기울기 폭발: 역 전파 처리시 기울기 값이 점점 커지다가 수직에 가까워지는 현상
  - 게이트 구조를 적용하여 개선 가능

### 2-5. RNN 모델의 개선 및 응용 (게이트가 추가된 RNN 모델)
- 게이트라는 구조를 활용하여 시계열 데이터의 장기 의존 관계를 학습할 수 있는 모델
- 게이트를 통하여 입력 및 출력의 상태(범위)를 제어함
- 데이터 기억을 위한 메모리 셀을 추가한 형태이며 데이터의 기억 여부, 상태도 제어함
- LSTM (Long-Short Term Memory networks) : RNN의 장기 의존성 문제를 해결할 뿐만 아니라 학습 또한 빠르게 수렴함
- GRU (Gated Recurrent Unit) : LSTM의 간소화된 버전이라고 볼 수 있음
<br><br/>

# 📈 LSTM 모델
![image](https://github.com/user-attachments/assets/78919e05-e75b-41d1-8a64-1ab4e9eac64a)

## 1. Memory Cell
### 1-1. 특징
- 데이터를 자기 자신으로만(LSTM 계층 내에서만) 주고 받음
- Memory Cell 𝒄𝒕 에는 시각 𝒕 에서의 LSTM의 기억을 저장함
  - 과거로부터 시각 𝑡 까지에 필요한 모든 정보가 저장되어 있다고 가정함
  - 또는 그렇게 저장되도록 학습 수행 → 𝒄𝒕의 정보가 지속적으로 갱신되고 있음을 의미
- 그리고 𝒄𝒕 의 정보를 바탕으로 외부 계층과 다음 시각의 LSTM 계층에 𝒉𝒕 를 계산하여 출력함

### 1-2. 계산하는 값
- 𝒄𝒕는 3개의 입력 (𝒄𝒕−𝟏, 𝒉𝒕−𝟏, 𝒙)로 부터 어떤 계산을 수행함
- 출력되는 은닉상태 𝒉𝒕 = 𝒕𝒂𝒏𝒉(𝒄𝒕) → 𝒄𝒕의 각 요소에 𝒕𝒂𝒏𝒉를 적용함을 의미
- 은닉상태 𝒉𝒕는 단순히 𝒄𝒕에 𝒕𝒂𝒏𝒉를 적용한 것 뿐이다 → 𝒄𝒕와 𝒉𝒕를 구성하는 원소의 수는 같다

### 1-3. 제어
- 3개의 Gate와 1개의 Updater의 제어를 받음
  - Output Gate, Forget Gate, Input Gate
  - Updater → New Memory Cell

![image](https://github.com/user-attachments/assets/738e31a7-4428-4b4f-a779-91c2cbf1b923)

![image](https://github.com/user-attachments/assets/aec30924-9b34-4d8c-b411-f62309bb232b)

![image](https://github.com/user-attachments/assets/68a4a804-83c5-4262-85b3-829356e8dda5)

### 1-4. 동작원리
- Forget Gate를 통해 이전 특징 별로 기억 여부를 결정
- Input Gate를 통해 현 시점의 정보가 얼마나 중요한지를 반영하여 기록
- 이전 Cell State의 결과와 현 시점의 Forget Gate에서 잊고, Input Gate의 중요도만큼 곱한 값으로 현 시점의 Memory Cell값을 생성
- 현 시점의 Forget Gate, Input Gate에 의해서 변경된 현 시점의 Cell State 값을 얼마만큼 다음 레이어로 전달할지 계산
  
![image](https://github.com/user-attachments/assets/a65997d6-88a3-4c73-95c7-0ccc574d1377)




















