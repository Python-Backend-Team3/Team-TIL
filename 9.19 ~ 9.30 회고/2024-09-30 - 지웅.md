# 📝 2024.09.30 회고 📝
#### 1. 수업 내용 복습정리
#### 2. 백준

---------------------------------

# AI란 무엇인가?
- 인공지능이란? 무엇인가?
![image](https://github.com/user-attachments/assets/4dca1dca-54d2-4b49-9000-6a9931c62222)


### 인공지능이란?
- 다양한 기술을 이용해 사람이 하는 일을 흉내 내어 처리할 수 있는 시스템
- 다양한 기술 : 기계, 전자, 컴퓨터 등 공학기술, 예술로 표현할 수 있는 창의성(목표)

### 인간의 지능에 대해 명확하게 밝혀지거나 정의되지 않음
- 인공지능의 구현 방향은 지능적인 것으로 보이는 것을 흉내 내어 보자 (인간을 흉내 내자로 귀결됨)
- 인간을 흉내내기 위한 방향성
  - 기계적인 부분을 흉내내자
  - 그 외의 부분들도 최대한 흉내 내보자
 
### 인간의 지능적(으로 보이는) 영역
- 기계적인 영역 : 5감과 운동
  - 시각 : Computer Vision -> 영상 인식, 분류, 영역구분 등 (사람의 인식 성공률 95%, AI : 98%)
  - 청각 / 발성 -> Audio 처리 기술 -> AI Speaker 등
  - 촉각, 후각, 미각 : 센서 기술 연구 수준에서 머뭄 (최근 성과가 조금씩 나오는 중)
  - 운동 : 로봇 기술을 이용한 동작, 자세 제어
 
- 비 기계적인 영역
  - 사고 : 현재 구현이 불가능 -> 데이터 처리, 의사결정, 언어처리 등으로 우회하여 구현

- 주변에서 쉽게 볼 수 있는 인공지능의 연구/산업 분야

### AI의 구분
![image](https://github.com/user-attachments/assets/e65eedef-aba5-490e-b294-40d6490873bd)

### AI 기술의 관계성
![image](https://github.com/user-attachments/assets/90448498-7a0d-4ea7-881c-e26410d73beb)

### AI 기술의 계통
![image](https://github.com/user-attachments/assets/8036a17d-c9ae-4253-b108-ec12d8210cc9)

### 인공지능의 유형
- 기호주의
  - 홉의 귀납문제:
    - 우리가 본 것에서 시작한 일반화를 -> 보지 못한 것에까지 적용하는 일을 어떻게 하면 정당화 할 수 있을까 -> 정당화 할 수 있는 근거가 없다면 우리가 본 몇가지 사례를 법칙으로 발전시킬 수 없음
  - 기호주의란 경험으로 얻은 지식, 사고 체계를 논리적으로 귀결 시키는 과정
  - 이러한 과정을 시스템으로 구현하는 것이 기호주의의 머신러닝
 
### 기호주의 머신러닝을 위한 하나의 예
![image](https://github.com/user-attachments/assets/401f1f27-295c-455a-a5b2-cfba00f68bbd)
- 이처럼 데이터의 패턴을 분석, 그 결과를 예측할 수 있도록 학습하는 것이 기호주의의 머신러닝

### 기호주의 머신 러닝의 문제점
- 우리가 발견한 패턴이 실제 존재하는가 -> 통계적 검증 필요, 수많은 데이터와 경우의 수
- 데이터에 적합한 단순한 가설을 선택하면 -> 사람이 편한 것이지 정확도, 성능 향상은 없음
- 기호주의 머신 러닝은 아는 것이 너무 적은 상태에서 학습 시작 -> 결승점 도달 실패 확률 높음
- 역연역법을 통해서 논리적으로 예측하는 방안 -> 나름대로 좋은 성과를 거둠
  - 너무 많은 규칙을 관리해야함 -> 계산량 문제 -> 해결?(의사결정 트리(스무고개 놀이) 등)
  - 잡음(무관한 데이터)에 쉽게 오류를 일으킴
  - 가장 큰 문제 : 실제 개념은 규칙의 모음으로 간결하게 정의되어 일이 거의 없다는 사실
 
### 연결주의
- 심리학자 "헵"의 규칙을 기반으로 만들어진 유형
- 헵 : 신경과학자보다 먼저 신경세포의 연결방식을 제안한 심리학자
- 헵의 규칙?
  - 시냅스의 앞과 뒤에서 동시에 신경세포가 흥분할 때, 해당 시냅스의 효율이 강화됨
  - 적당한 추측을 기반으로 심리학과 신경과학의 착상들을 통합해 놓음

### 연결주의 머신러닝의 개념
- 각 개념(데이터)와 기억은 두뇌에서 세포의 모임으로 나타냄
- 개념(데이터)는 모든 곳에 조금씩 저장되어 있다
- 두뇌는 수십억의 신경세포가 동시에 동작하며 많은 계산을 수행한다, 그러나 각 신경세포는 1초에 1000번 정도 반응하므로 계산이 느리다(병렬시스템)
- 신경 세포에는 수천개의 신경 접합부가 있다
- -> 두뇌가 어떻게 만들어지는가 이해해야 두뇌를 시뮬레이션(모의 실험)할 수 있으며 인공지능(머신러닝)은 두뇌를 재 구축함으로써 구현 가능하다.

### 연결주의 머신 러닝의 문제점
- 두뇌, 신경의 구조, 작용 등에 대하여 아직 모르는 부분이 너무 많음
- 연결주의 등장 당시의 기준으로 컴퓨터의 성능이 지나치게 낮음(구현 불가능)
- 병렬처리해야 하는 데이터가 너무 많음

### 진화주의
- 진화론에서 출발한 진화, 돌연변이를 통해 학습을 수행하는 유전자 알고리즘 중심 연구
- 연결주의(신경망)연구자 홀랜드가 생물학자 겸 통계학자 로널드 피셔의 "자연 선택의 유전 이론" 논문을 접한 후 제안한 이론을 기반으로 함
- 가장 적응력이 높은 유전자만 살아남고 살아남은 유전자가 가장 정확한, 또는 적절한 결과를 도출한 가능성이 크다.
![image](https://github.com/user-attachments/assets/41d5d057-86ca-40b5-9502-e4003d308326)

### 베이즈 주의
- 통계학 일부인 베이즈 정리를 기반으로 한 머신러닝
- 어떤 원인에서 어떤 결과가 일어날 가능성이 높을 수록 그 결과가 나타났을 때 그것이 원인일 가능성이 높다(확률적 기반)
- 원인과 결과, 즉 인과관계에 대한 추론을 기반으로 학습, 예측을 진행
- 인간은 언어 추리가 연관되면 베이즈 추론을 매우 잘 하는 것은 아님, 인간은 원인의 사전 확률을 무시하는 경향이 있다.
![image](https://github.com/user-attachments/assets/414a4990-c595-4386-8662-77f43e963f74)

### 유추주의
- 사물, 현상에 대한 유추를 기반으로 학습을 진행하는 연구
- 통계학에서 먼저 알고리즘화 되기 시작했으며 컴퓨터 과학 전 분야에서 많은 연구가 진행되고 있는 분야
- 신경망, 기호주의, 유전자 알고리즘 등 다양한 머신 러닝 모델에도 영향을 끼침

### 유추주의 개념의 예시
- 역사상 악명높은 사기꾼 – 프랭크 애버그네일 주니어
- 의학적인 교육은 전혀 받지 않은 채로 1960년대 후반 애틀란타에서 1년 가까이 의사로 행세함
- 아무도 모르게…
- 행위
  - 빈 진료실에 들어감 → 아무것도 모르는 환자 입실 → 환자의 증상을 들음 → 캐비닛에 들어있는 환자들의 진료 기 록 검색 → 유사한 다른 환자의 기록을 꺼내어 동일한 진단 내림 → 1년 가까이 아무도 의심하지 않음

### 5가지 연구 유형에서…
- 모든 것을 만족하는 알고리즘은 아직까지 나오지 않았음
- 각 유형은 각각의 장, 단점을 가지며 어느 하나가 완벽한 모델은 없음
- 최근의 추세는 각 유형이 서로 융합, 협력하여 서로의 단점을 보완하려는 움직임을 보이고 있음
- 새로운 연구를 위해서도 서로의 장, 단점을 잘 알고 활용할 필요가 있음

### 최근의 인공지능 기술의 변화 추세
- 다양한 모델의 통합
  - 매우 다양한 모델이 존재함
  - 기존의 모델이 딥러닝 모델로 대체되는 경우가 많음
  - 기존 모델과 딥러닝 모델이 결합하는 경우도 많음
- 자연어처리 기술 → 언어모델 → 초거대AI → ChatGPT
  - 언어 처리 기술이 현재의 최대 이슈가 되고 있음

### AI 기술은 컴퓨터를 기반으로 프로그램의 형태로 구현됨
- 컴퓨터 프로그램이란?
  - 보유한 데이터를 입력하여
  - 우리가 원하는 결과 데이터를 만들어 내도록 지시하는
  - 명령어의 모임

![image](https://github.com/user-attachments/assets/c01290b9-3d43-4c92-92d8-c97e08a02db9)
![image](https://github.com/user-attachments/assets/7ead92ac-4f5a-431e-b0d7-ca0b259ed0cc)
![image](https://github.com/user-attachments/assets/70933333-0cdd-46ef-8789-6c60bc434f59)

### AI 기술의 분류
![image](https://github.com/user-attachments/assets/fe70ac5a-aaff-49b9-b5d9-a9aaa63a3df2)


# 딥러닝 개요

### 딥러닝 감잡기
- 어떤 생각으로 딥러닝을 접근해야하는지 학습

#### 잘 익은 귤 분류하기
- 문제제시
 - 2개의 상자가 있음
  - 잘 익은 귤 상자
  - 덜 익은 귤 상자
- 분류 주체
 - 일단 사람이 먼저 분류
 - 사람이 분류하는 내용을 보면서 감을 잡고, AI 머신을 이용해서 분류
  - AI 머신에서는 프로그램을 작성해서 분류하게 됨

#### 사람의 분류 과정
-  귤을 잔뜩 모아 놓고 분류를 시작함
-  잘 익은 귤과 덜 익은 귤을 각각 상자에 나눠 넣음     귀찮음
-  뭔가 고정된 분류 기준이 있으면 좋겠다
  - 잘 익은 귤을 보니 대체로 크고 덜 익은 귤은 작더라
  - 대충 크기를 재어보니 잘 익은 귤은 지름이 7.5cm 이상이다.
- 귤의 지름이 7.5cm인 것을 기준으로 분류하자 프로그램 작성
  - → AI 머신의 분류 작업으로
 ![image](https://github.com/user-attachments/assets/a192de4a-a185-49a4-85af-1e4a712bb105)

- AI 머신의 작업결과를 보고 있으니...
  -  가끔씩 7.5cm 미만의 귤 중에 잘 익은 것이 나온다.
  -  가끔씩 7.5cm 이상의 귤 중에서도 덜 익은 것이 나온다.
  -  하드 코딩한 AI 머신의 프로그램을 바꿔야할 것 같다....
  -  → 하드 코딩한 기준도 스스로 찾아내도록 하고 싶다..
 ![image](https://github.com/user-attachments/assets/94589e9f-054f-459f-9c8e-3a66bf1badaa)

#### 잘 익은 귤 분류하기
- 사람이 찾은 기준과 직접 하드 코딩한 프로그램(알고리즘) → ①
- AI 머신이 찾은 기준과 기준을 찾을 때 사용한 알고리즘 → ②
- ②의 경우가 딥러닝을 적용한 알고리즘의 개념임
- 서로 다른 방식을 사용하여 기준을 찾았지만 ①과 ②의 목적과 사용 방향은 동일함

### 신경망 모델이란?
- 신경세포의 간단하고 효과적인 처리 방식에 착안해 구현된 머신 러닝 모델의 한 종류
- 신경세포의 형태와 동작을 극도로 다순화 시킨 뉴런 모델 다수를 연결해 네트워크를 구성함
 - 다량의 뉴런들이 층(layer)로 연결되어 간단한 계산과 연결 방식을 통해 복잡한 문제를 해결하는 모델
- 뉴런의 동작 방식은 컴퓨터 프로그램의 방식에 비해 다양한 장점을 지님

![image](https://github.com/user-attachments/assets/eef94dbb-1585-4af5-b81b-1204e5c19fb0)

- 헵의 규칙이 신경망 모델의 동작을 정의하는 기반이 됨
 - 시냅스의 압과 뒤에서 동시에 신경세포가 흥분할 때, 해당 시냅스의 효율이 강화된다.

### 신경세포의 구조
![image](https://github.com/user-attachments/assets/37ad8849-a0f8-451a-927b-63f45aab0b99)

### 신경세포의 연결 형태
![image](https://github.com/user-attachments/assets/ea7f53cf-9171-4fdd-8a2e-40068cb29294)

- 신호의 전달은 전기로 이루어짐
- 신경세포의 말단에는 시냅스가 존재
- 시냅스 사이의 신호 전달은 신경전달물질이라는 화학 물질을 통해전달됨
- 신경전달물질
  - 세로토닌
  - 도파민
  - 엔돌핀
  - 아드레날린 등..

### 신경세포의 신호 처리 과정
- 신경체계를 구성하는 수많은 신경세포들
- 다양한 감각기관을 통하여 (전기)신호를 발생, 전달
- 각 신경세포는 수많은 시냅스를 통해 신호를 전달 받음
- 전달 받은 신호는 대체로 무시하지만.. 동시에 전달된 신호의 합이 임계값을 넘으면 활성화 (발산, 흥분한다 라고 표현함)
- 활성화 된 신경세포는 활성화 패턴에 따라 신경전달물질 분비
- 이웃 신경세포는 신경전달물질을 수용하면서 이온화 작용, 화학작용을 통하여 전기 신호 발생
- 처리 단계 반복

### 퍼셉트론(Perceptron) 모델 
- 1958년, 심리학자 프랭크 로젠블랫(Frank Rosenblatt)이 개발한 신경망 모델
  - 당시의 인공지능-신경망 모델 중 가장 유명한 모델
- 1960년, 로젠블랫과 동료들은 퍼셉트론이 유한하게 많은 훈련 주기에서 매개변수가 구현할 수 있는 모든 작업을 학습할 수 있음을 보여줌
  - 퍼셉트론 수렴 정리는 단층 신경망에 대해 입증됨
  - 당시의 신경망 연구는 상당수의 개인이 취한 뇌-기계 문제에 대한 접근 방식이 중심이었음
  - 뉴욕타임즈의 보고서와 로젠블랫의 진술에 따르면 신경망은 곧 이미지를 보고, 체스에서 인간을 이기며 번성할 수 있을 것이라고 주장함
- 비슷한 시기에 등장한 기호처리 기반의 인공지능 연구 그룹과 자금 및 인력을 놓고 경쟁하게 됨
![image](https://github.com/user-attachments/assets/380f3bde-55f5-48fe-8085-17ca9cbbf61c)

### 단층 퍼셉트론(SLP, Single Layer Perceptron)
![image](https://github.com/user-attachments/assets/aff43046-70f8-4b47-9880-95a8915f6b8b)

- 다수의 퍼셉트론이 하나의 층을 이루고 있는 형태
- 센서 데이터 등 다양한 데이터를 각 퍼셉트론의 입력으로 전달
- 각 퍼셉트론은 입력된 데이터를 모아서 합산
- 합산 결과가 임계 값을 넘으면 1, 넘지 않으면 0 출력
- 입력층에서 각 퍼셉트론으로 진행되는 통로에는 가중치 적용 (가중치는 모든 통로가 각각 다르게 적용될 수 있음)
- 왼쪽 그림에서 4개의 퍼셉트론이 각각 1, 0, 0, 1 이라는 결과를 낸다면, 최종 출력은 1001 이라는 2진수 값이 나오는 형태

- 한 층의 변경가능한 퍼셉트론만 존재
  - → 1개의 선을 그어 분리 가능한 패턴만 분류 가능
  - → XOR 문제의 원인한 층의 변경가능한 퍼셉트론만 존재
  - → 1개의 선을 그어 분리 가능한 패턴만 분류 가능
  - → XOR 문제의 원인
![image](https://github.com/user-attachments/assets/dde4a650-b9ae-4130-9855-d3adac4ebe97)

- 단층 퍼셉트론의 구조를 보면
- 가중치를 변경할 수 있는 방법이 없다 → 학습이라는 개념이 없다
- 한 번 생성된 후에는 아무런 변형이 없는 단순한 분류 알고리즘에
불과함

# 다층 퍼셉트론

### XOR 문제의 해결 방안 등장
![image](https://github.com/user-attachments/assets/14c3181b-e2d9-410d-93bc-c4a7cc5e4054)

- 직선으로 데이터 분류하기
![image](https://github.com/user-attachments/assets/878ce51f-6eb1-47aa-ac86-5c15f16a480c)

- 직선의 수를 늘림으로써 다양한 패턴의
분류가 가능해 짐
- XOR 문제의 원인 제거 성공
- 다층 퍼셉트론 등장

![image](https://github.com/user-attachments/assets/911acd61-c216-41b9-ad27-44e56228c9f5)
- 다수의 퍼셉트론 층이 네트워크를 이루는 형태
- 처리 방식은 단층 퍼셉트론과 동일함

## 다층 퍼셉트론
- 단층 퍼셉트론과 마찬가지로 각 통로의 가중치를 변경할 방법이 없다
- 한 번 생성되면 변경 불가능한 분류 알고리즘
- 역시 학습의 개념이 없다 → 인공지능이 아닌 단순한 분류 알고리즘

- 해결책
 - 수행할 때마다 예전 데이터를 들고 와서 가중치를 수정해 주면 어떨까?
 - 그럼 아예 앞뒤로 왔다 갔다 반복하면서 가중치를 바꾸어 주면 어떨까?
 - Back Propagation (역전파) 알고리즘이 제안되어 왔으며
   - 1986년 Rumelhartt D. E., Hinton G. E, William R. J.의 “Learning representations by back-propagation errors” 논문에서 성공적으로 적용함
  
#### Back Propagation (역전파) 알고리즘
![image](https://github.com/user-attachments/assets/9eb08113-376c-44eb-90fe-939796a81155)
![image](https://github.com/user-attachments/assets/35f2facd-ef3c-44f3-b4cd-024e8937586b)

#### 역전파 시 어떻게 가중치를 조절하는가?
 - 조절 내용: 은닉층을 거친 결과값과 기대한 결과값의 오차를 줄이는 방향으로 수정
![image](https://github.com/user-attachments/assets/783efb09-b506-4855-b9bd-f86e47ed29ea)

![image](https://github.com/user-attachments/assets/fb5f07f8-e9e4-4e29-8d45-76d72164b120)
![image](https://github.com/user-attachments/assets/89976a87-641b-457a-9711-d58ee51111b3)
![image](https://github.com/user-attachments/assets/491bbf41-d192-42e9-be1a-e86baeefbd54)

#### Back Propagation (역전파) 알고리즘을 구현한 다층 신경망에서
- 그 층을 훨~씬 많이 만들어서
- 수 많은 분류 작업을 수행할 수 있게 한다면?
- 다층 신경망(Multilayer Neural Network) 
  - → 심층 신경망(Deep Neural Network) 으로 진화 
- 심층 신경망을 이용한 학습 모델 = 딥 러닝(Deep Learning)

#### 가장 기본적인 딥러닝 모델 : 전체 구조
![image](https://github.com/user-attachments/assets/66b690e7-43f5-4a5c-b96c-8d6b1d749d30)

### 입력층
![image](https://github.com/user-attachments/assets/18e75cbc-9e00-4020-8602-a43da65dc0d4)

##### 이미지 / 영상 데이터가 왜 수치 데이터인가?
- 이미지 데이터는 색깔을 가진 수많은 점이 가로x세로 크기의 2차원 배열 속에 모인 데이터
![image](https://github.com/user-attachments/assets/c6e343aa-dd81-4000-b83b-93884b934706)

### 은닉층
![image](https://github.com/user-attachments/assets/b823bcf8-b484-4f53-b54d-4b75c2b5d4b9)
![image](https://github.com/user-attachments/assets/fc9fd0ef-1dcf-4900-8937-6a500b3a117d)
![image](https://github.com/user-attachments/assets/4dcbe4e2-c200-4653-9142-3aba309fa476)
![image](https://github.com/user-attachments/assets/71988cfe-c021-49b5-927a-e168e63bdc5d)
![image](https://github.com/user-attachments/assets/da8fc1c0-2753-49b3-8c0f-7b3a69176f6c)

### 딥러닝 기본 모델
![image](https://github.com/user-attachments/assets/d95af5b9-9a07-4557-8305-188e5f2b14ce)

### 활성화 함수
- 그럼 여기서… 각 퍼셉트론에서 임계 값을 넘으면 활성화는 어떻게 하나?
- 활성화 함수
  - 신경망을 구성하는 각 퍼셉트론에서 임계 값을 넘었을 때 출력을 처리하는 함수
  - 정의
    - 입력 : 이전 층의 디바이스 또는 퍼셉트론들로부터 전달되는 데이터
    - 함수의 동작 : 입력 값의 합산 + 합산결과과 임계 값의 비교 + 출력 결정 (솰성화 조건)
    - 출력 : 퍼셉트론 층의 연산 결과값. 다음 층의 뉴런에 대한 입력 또는 최종 층의 출력
   
### 활성화 함수가 필요한 이유
- 생물학적 / 신경과학적 필요성
  - 피부, 눈과 같은 감각기관이 어떤 자극을 받아 신호를 발생시키면
  - → 그 신호는 축삭을 통해서 이동하고 → 축삭의 말단에 있는 시냅스를 거쳐 → 다음 뉴런으로 전달
  - 그런데 전달되는 모든 신호(아주 미세한 신호부터 강한 신호까지)를 모두 다음 뉴런으로 전달한다면?
    - 생활/생존 자체가 어려워지며 매우 비 효율적
    - 우리 몸에서 반응할 필요가 있는 수준까지만 신호를 전달하고 나머지의 신호는 무시한다!! → 진화의 결과
    - 이 기준을 모델에 반영한 것이 활성화 함수
- 수학적 필요성
  - 입력 데이터는 연속, 선형 데이터이지만 출력 데이터는 이산 데이터(예측 및 분류 등)
  - → 선형성을 가진 데이터를 비선형성을 가진 데이터로 변환시킬 필요가 있음

### 활성화 함수란
- 뉴런의 신호 흐름을 모델링 할 때 각각의 뉴런에 제한을 걸어 둔 것
- 









```
