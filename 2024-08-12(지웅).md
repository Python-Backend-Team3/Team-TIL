# 데이터베이스 및 데이터 분석 개요

## 1. 개념적 데이터 모델링 (Conceptual Data Modeling)
- 개념적 데이터 모델링은 사용자의 요구사항을 바탕으로 데이터를 추상적으로 모델링하는 초기 단계
- 특정 데이터베이스 관리 시스템(DBMS)에 종속되지 않는, 업무 중심적이고 포괄적인 수준의 데이터 모델을 구축

- **주요 작업**: 엔티티(Entity)와 그 관계(Relationship)를 중심으로 전반적인 데이터 구조를 파악
- **산출물**: 주제 영역, 주요 엔티티, 주요 속성(Attribute), 식별자(Identifier) 및 엔티티 간의 관계 등을 도출하여, 이를 개념적 스키마로 표현
- **ERD**: 개념적 데이터 모델은 ERD(Entity-Relationship Diagram)와 같은 다이어그램으로 시각화할 수 있다.

## 2. 논리적 데이터 모델링 (Logical Data Modeling)
- 논리적 데이터 모델링은 개념적 데이터 모델을 바탕으로 좀 더 구체적이고 상세하게 정의하는 단계
- 데이터베이스 구현을 염두에 두고, 개발에 사용될 특정 DBMS에 적합한 모델로 변환

- **주요 작업**:
  - 엔티티를 릴레이션(Relation)으로 변환: 각 엔티티는 하나의 테이블로 변환
  - 관계 표현:
    - 일대일(1:1) 및 일대다(1:N) 관계는 외래키(Foreign Key)로 표현
    - 다대다(N:N) 관계는 별도의 릴레이션(중간 테이블)으로 변환
  - 식별 관계와 비식별 관계: 부모 릴레이션과 자식 릴레이션 간의 관계를 정의.
  - 식별 관계는 부모 릴레이션의 기본키가 자식 릴레이션의 기본키의 일부로 사용되는 경우이며
  - 비식별 관계는 부모 릴레이션의 기본키가 자식 릴레이션의 기본키에 포함되지 않는 경우

## 3. 물리적 데이터 모델링 (Physical Data Modeling)
- 물리적 데이터 모델링은 논리적 데이터 모델을 실제 데이터베이스 시스템에 맞게 구현하는 단계
- 테이블 구조, 컬럼의 데이터 타입, 인덱스, 참조 무결성 등의 세부 사항을 결정

- **주요 작업**:
  - 테이블 설계: 기본키 컬럼 순서, 데이터 타입, 컬럼명 매핑 등을 결정
  - 제약조건 설정: 인덱스 생성, 참조 무결성 규칙 정의, 파티셔닝 등의 세부 사항을 정의
  - 저장 구조와 접근 경로 결정: 데이터 저장 방식과 데이터 접근 경로를 최적화

## 4. 구현, 유지보수, 검증 및 최적화
- 물리적 데이터 모델이 완성되면 이를 기반으로 실제 데이터베이스를 생성하고 운영하게 된다. 
- 데이터베이스 운영 중에도 필요에 따라 모델을 조정하거나 확장하는 유지보수 작업이 이어지며,
- 데이터 모델의 정확성, 일관성, 성능 등을 검증하고, 필요시 최적화를 진행한다.
- 각 단계의 산출물을 문서화하여 데이터베이스 관리와 유지보수에 활용할 수 있도록 한다.

## 데이터베이스 정규화 (Normalization)

### 1. 이상(Anomaly)
- 이상 현상은 관계형 데이터베이스에서 데이터 삽입, 삭제, 수정 시 발생할 수 있는 불일치나 오류를 의미

- **삽입 이상(Insertion Anomaly)**: 새로운 데이터를 삽입할 때 불필요한 데이터를 반복해서 입력해야 하는 경우 발생
- **삭제 이상(Deletion Anomaly)**: 데이터를 삭제할 때 발생하는 문제로, 삭제할 필요가 없는 다른 정보도 함께 삭제되는 경우
- **수정 이상(Update Anomaly)**: 데이터를 수정할 때 테이블의 일부 레코드만 수정되어 데이터의 일관성이 깨지는 경우

### 2. 함수적 종속성(Functional Dependency, FD)
- 함수적 종속성은 관계형 데이터베이스에서 속성 간의 관계를 나타내는 개념으로, 한 속성의 값이 다른 속성의 값을 고유하게 결정하는 경우를 의미

- **정의**: `X → Y`: 속성 X의 값이 주어지면 속성 Y의 값이 항상 유일하게 결정된다. 여기서 X는 결정자(Determinant), Y는 종속자(Dependent)이다.
- **함수적 종속성 다이어그램(Functional Dependency Diagram, FDD)**: 함수적 종속성을 시각적으로 표현하는 도구로, 속성 간의 관계를 쉽게 파악할 수 있게 도와준다.

### 3. 함수적 종속성의 유형
- **완전 함수적 종속성(Full Functional Dependency)**: 기본키가 아닌 속성들이 기본키에 종속이 되는 종속 관계. 기본키가 복합키인 경우에는 기본키를 구성하는 속성 집합에 종속되어야 한다.
- **부분 함수적 종속성(Partial Functional Dependency)**: 기본키가 아닌 속성들이 기본키의 일부에 종속되는 관계이다.
- **이행 함수적 종속성(Transitive Functional Dependency)**: 세 개 이상의 속성이 연결되어 있을 때 발생하는 종속 관계이다.
  - X → Y, Y → Z와 같이 속성 간에 종속성이 연쇄적으로 전파되는 경우
  - Y가 X에 함수적으로 종속되고, Z가 Y에 함수적으로 종속되면, Z는 X에 대해 이행 함수적으로 종속된다.

### 4. 데이터베이스 정규화(Normalization)
정규화는 데이터베이스 설계의 중요한 개념으로, 이상을 제거하여 데이터베이스를 효율적으로 구조화하는 과정

- **제1정규형(1NF)**: 테이블의 모든 속성이 원자값(Atomic Value)으로만 구성되도록 분해, 반복 그룹이 없고, 중복되는 속성이나 속성 그룹은 별도의 테이블로 분리한다.
- **제2정규형(2NF)**: 제1정규형을 만족하면서, 기본키가 아닌 속성들이 기본키 전체에 대해 완전 함수적 종속성을 가지도록 분해한다.
- **제3정규형(3NF)**: 제2정규형을 만족하면서, 비기본키 속성들이 다른 비기본키 속성에 종속되지 않도록 한다.
- **추가 정규형**: 보이스-코드 정규형(BCNF), 제4정규형(4NF), 제5정규형(5NF) 등이 있으며, 실무에서는 주로 제3정규형까지 진행한다.

### 5. 반정규화(Denormalization)
- 반정규화는 중복 데이터를 하나 이상의 테이블에 추가하여 데이터베이스 성능을 향상시키는 기술이다.

- **장점**:
  - 조인 개수를 줄일 수 있고, 이로 인해 검색 쿼리가 간단해진다.
  - 빠른 읽기 작업의 수행으로 인해 검색 성능을 높일 수 있다.
- **단점**:
  - 중복 저장으로 인해 더 많은 스토리지가 필요하다.
  - 데이터 불일치가 발생할 수 있다.
  - 쓰기 작업에 추가적인 비용이 소요될 수 있다.

## 데이터 분석

- 데이터 분석은 다양한 도구를 사용하여 데이터를 분석하고 해석하여 조직의 목표 달성에 도움이 되는 통찰력과 추세를 제시하는 과정이다.

### 1. 데이터 분석 단계
- **문제 정의**: 해결하고자 하는 문제와 필요한 데이터를 정의
- **데이터 수집**: 공공 데이터, 센서 데이터, SMS/REST API 등을 통해 데이터를 수집
- **데이터 전처리**: 데이터를 정규화하고, 이상치, 누락된 값(결측치), 잘못된 값 등을 처리하며 데이터 형을 일치화
- **탐색적 데이터 분석(EDA)**: 데이터의 특성을 확인하고 파악
- **모델링**: 데이터에 적합한 모델을 구축하고 학습
- **평가**: 모델의 성능을 평가
- **결과 해석**: 분석 결과를 해석하고 인사이트를 도출
- **배포 및 보고서 작성**: 분석 결과를 공유하고 문서화

### 2. 데이터 분석 도구
- **통계 분석용 도구**: Excel, R, SAS, SPSS 등
- **비즈니스 인텔리전스 도구**: Power BI, Tableau 등
- **프로그래밍 언어 기반 도구**: Python, SQL 등

### 3. SQL을 활용한 데이터 분석
- **데이터 추출**: 데이터를 수집
- **데이터 필터링 및 정렬**: 필요한 데이터를 필터링하고 정렬
- **집계 및 그룹화**: 데이터를 집계하고 그룹화
- **조인 및 서브쿼리**: 여러 테이블의 데이터를 결합하거나 서브쿼리를 사용
- **데이터 변환 및 처리**: 데이터의 변환 및 처리 작업을 수행
- **데이터 시각화**: 시각화 준비를 위한 기반 데이터를 생성

### 4. 데이터 분석을 위한 데이터 소스
- **내부 데이터**: 조직 내에서 생성된 데이터, 입력 실수를 고려해야 하며 품질 검증이 필요
- **외부 데이터**: 웹 스크래핑, 사용자 생성 콘텐츠, 업계 데이터, 연구 데이터, 애널리틱 데이터 등.
